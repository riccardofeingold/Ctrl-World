# Experiment: 10fps with hand mask
experiment:
  experiment_name: "orca_10fps_highres"
  experiment_description: "Training with 10fps data and hand segmentation masks"
  
# Override base config parameters
training:
  tag: "orca_10fps_high_res_sine_object_collision_fixed_ee_fixed_cam"
  output_dir: "model_ckpt/${training.tag}"
  wandb_run_name: "${experiment.experiment_name}_${training.tag}"
  wandb_project_name: "orca_experiments"
  
  debug: false
  learning_rate: 1e-5
  gradient_accumulation_steps: 1
  mixed_precision: "fp16"
  train_batch_size: 4
  shuffle: true
  num_train_epochs: 100
  max_train_steps: 100000
  checkpointing_steps: 10000
  validation_steps: 2500
  max_grad_norm: 1.0

  video_num: 4
  num_validation_batch: 2

dataset:
  dataset_root_path: "datasets/2025-12-24T01-20-32"
  dataset_names: "data_fix_cam_fixed_ee_sine_object_collision_high_res_10fps"
  dataset_meta_info_path: "dataset_meta_info"
  dataset_cfgs: ${dataset.dataset_names}  # Reference from dataset section
  annotation_name: "annotation"
  prob: [1.0]  # Use only one dataset
  original_fps: 50
  down_sample: 5  # 50/10 = 5
  skip_step: 1
  num_workers: 4
  use_hand_mask: false
  max_num_samples: 13000

model:
  # Model paths
  svd_model_path: "stabilityai/stable-video-diffusion-img2vid"
  clip_model_path: "openai/clip-vit-base-patch32"
  ckpt_path: null
  pi_ckpt: null  # Policy checkpoint for rollout (not needed for training)
  
  # Model architecture
  action_dim: 23
  action_encoder_hidden_dims: [1024]
  vae_compression_rate: 8
  text_cond: false
  frame_level_cond: true
  his_cond_zero: false
  num_views: 1
  only_wrist_view: false
  
  # Training/inference settings
  dtype: "bfloat16"  # Options: "float32", "float16", "bfloat16"
  hand_weight: 2.5
  motion_bucket_id: 127
  guidance_scale: 2.0
  num_inference_steps: 50
  decode_chunk_size: 5
  
  # Frame dimensions
  width: 256
  height: 256
  num_frames: 5
  num_history: 5
